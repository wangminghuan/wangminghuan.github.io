---
title: 主流大模型概述
lastUpdated: 2024-06-30 14:05:12
---

## 全球公司AI模型

### OpenAI
> 美国人工智能研究
- ChatGPT 是 OpenAI 的一个大模型，基于 Transformer 架构，具有强大的理解能力和生成能力。
- ChatGPT 3.5/3.5 Turbo,ChatGPT 4/4 Turbo, ChatGPT 4o/4o Turbo
- GPT-4o 是 GPT-4 Turbo 的升级版本,"o"代表"omni"，意为"所有"或"通用"。

### Anthropic
> OpenAI核心成员创建的
- Claude 3 Haiku 是 Anthropic 的轻量级模型，速度快，成本低。
- Claude 3 Sonnet 是 Anthropic 的次旗舰模型，性能均衡，成本适中。
- Claude 3 Opus 是 Anthropic 最新发布的旗舰模型，具有强大的理解能力和生成能力。
- Claude Code 是 Anthropic 的代码生成模型，基于 Claude 3 系列，专为代码生成任务而设计。


### Meta （开源）
> 元宇宙，前身为Facebook
- Llama 3.1/Llama 3.2 是 Meta 的最新大模型，支持开源生态构建、低资源部署

### Mistral AI（开源）
> Mistral AI（法国）
- Mistral 3 系列是 Mistral 的最新大模型，支持开源生态构建、低资源部署，推理速度比同量级模型快30%+

### Mricrosoft（开源）
- 微软 Phi 系列 主打小参数、强性能、低成本、易部署，是目前最具性价比的小型语言模型（SLM） 之一，从代码专项起步，逐步扩展到通用、推理、多模态，覆盖从边缘设备到云端的全场景。

### Google（开源）
> 谷歌AI研究
- Gemini 1.5 Pro 是 Google 的最新大模型，支持开源生态构建、低资源部署，推理速度比同量级模型快30%+ 

## Hugging Face/ServiceNow
> BigCode 是一个开源协作组织, Hugging Face 牵头 + NVIDIA、ServiceNow、GitHub、剑桥大学等
- StarCoder 是 BigCode 项目推出的开源代码大模型，主打多语言、长上下文、FIM 训练、开源可商用，从 StarCoder 1 到 StarCoder 2 完成了从单尺寸到全尺寸

### 字节跳动
> 北京引力弹弓(Trae)是字节全资子公司
- Doubao 是字节跳动的大模型，基于 Transformer 架构，具有强大的理解能力和生成能力。
- Doubao 1.8 是 Doubao 模型的一个版本，2.0版本将于 2.14 发布，具有更强的理解能力和生成能力。

### Minimax AI
>成立于 2021 年，由前商汤科技高管闫俊杰创立
- 目前主打的三款产品分别为：MiniMax API开放平台、海螺AI和星野
- 以文本（M 系列）、语音（Speech）、音乐（Music）、视频（Hailuo）、图像（Image） 五大产品线为主，主打Agent 原生、速度快、成本低、多模态协同

### 深度求索（开源）
> 2023年7月，梁文锋创立了DeepSeek
- DeepSeek 是一个基于 Transformer 架构的大模型，支持开源生态构建、低资源部署。
- DeepSeek 主要分为 V 系列（通用型）、R 系列（推理 / 代码 / 数学专精） 两大技术路线，另有 Coder 系列（代码专项）

### 智谱AI（开源）
> 智谱华章是清华大学深度孵化、技术成果产业化的 AI 
- GLM-4（基础版）/ GLM-4 Turbo / GLM-4 Air / GLM-4 Opus 是 2025年发布的模型，
- GLM-5 Opus 是 2026年发布的最新模型，具备动态 MoE + 全模态统一

### 百川智能（开源 + 闭源）
> 是由王小川（搜狗CEO）和茹立云于2023年4月10日联合创立
- 百川智能（Baichuan AI）是国内主流闭源 + 开源并行的大模型厂商，主打中文强、长上下文、低幻觉、企业级性价比。

## 阿里（开源）
> 阿里达摩院
- 通义千问 Qwen1.5/Qwen 2/Qwen 2.5/Qwen 3，主打中文极强、长上下文、多模态、开源友好、企业级性价比，覆盖从 0.5B 轻量到 235B MoE 旗舰全尺寸，

## 百度
- 文心一言 3.0/4.0/4.5/x1/5.0。核心优势是中文极强、知识增强、多模态原生、工具 / Agent 成熟、企业生态完善，从早期通用到 5.0 原生全模态、X1 深度思考全面覆盖（截至 2026-02-14）。

## 上海AI实验室
- InternLM（书生・浦语）主打强推理、长上下文、工具调用、科学多模态，从 1.0 到 3.0 持续迭代，

## 月之暗面
> 成立于2023年4月17日，法定代表人杨植麟
- Kimi AI 核心优势是超长上下文、强推理、多模态、Agent 集群，从 V1/K1.5/K2/K2.5 能力持续跃升

## AI编程工具

### Cursor
> AI原生IDE（基于 VS Code）/主打专注深度代码理解
- Anysphere（2022 年 MIT 毕业生创立）。
- GPT-4o、Claude 3.7、Gemini 1.5 Pro（多模型切换）
- 项目级代码理解/智能调试与重构/多模型并行推理/函数调用优化

### GitHub Copilot
> AI 代码补全插件/主打代码补全功能
- GitHub+Microsoft+OpenAI 联合开发
- GPT-4o、Copilot CodeLlama（混合模型）
- 实时代码补全（接受率 85%+）/ GitHub 生态深度集成

### CodeLlama
> 开源代码大语言模型/主打开源免费与本地部署
- Meta（元宇宙）- Facebook
- 自研 CodeLlama 系列（基础版 / Python 专用 / 指令跟随）
- 支持 20 + 编程语言 / 本地部署（离线运行）

### TRAE
> AI原生IDE/插件（基于 VS Code）/主打全流程智能体与免费策略
- 字节跳动
- GPT-4o、Claude 3.5 Sonnet、字节豆包 1.5 Pro（全免费）
- SOLO 智能体全流程驱动/多模态交互/Builder 模式/中文语境深度优化
- TRAE可以理解为是MarsCode的升级版，包含IDE 和 插件

## 核心AI模型速览表
| 模型家族 | 代表版本 | 机构 | 核心定位 | 最强能力 | 多模态 | 上下文 | 是否开源 | 幻觉率 | 适用场景 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **GPT** | GPT‑4o / o1 | OpenAI | 通用全能天花板 | 综合能力、实时交互、多模态 | ✅ 全模态 | 128K | ❌ 闭源 | 极低 | C端、高端产品、复杂推理 |
| **豆包** | Doubao 2.0 | 字节跳动 | 中文体验最优 | 中文、视频理解、日常交互 | ✅ 全模态 | 256K | ❌ 闭源 | 低 | 中文用户、内容创作、短视频 |
| **GLM** | GLM‑5 Opus | 智谱AI | 中文企业级全能 | 中文、低幻觉、长文本、Agent | ✅ 全模态 | 256K | ⚠️ 部分开源 | 极低 | 金融、法律、政务、高可靠 |
| **DeepSeek** | DeepSeek‑R1 | 深度求索 | 推理/代码之王 | 数学、逻辑、深度思考、代码 | ❌ 弱 | 128K | ✅ 全开源 | 中 | 科研、编程、数学、私有化 |
| **Kimi** | Kimi K2.5 | Moonshot | 长文本精读之王 | 超长文档、PDF/Excel/PPT解析 | ✅ 图文 | 200K+ | ❌ 闭源 | 低 | 文档阅读、办公、知识库 |
| **Qwen** | Qwen 3 Max | 阿里云 | 均衡全能企业级 | 工具调用、稳定、性价比 | ✅ 图文音 | 200K | ⚠️ 部分开源 | 中低 | 企业API、私有化、通用场景 |
| **Claude** | Opus 4.6 | Anthropic | 安全合规长文本 | 超长上下文、高可靠性 | ✅ 图文音 | 1M | ❌ 闭源 | 极低 | 合规、法律、医疗、超长文本 |
| **Gemini** | 3 Pro | Google | 搜索+多模态 | 知识检索、跨模态、谷歌生态 | ✅ 全模态 | 1M | ❌ 闭源 | 中 | 海外、搜索增强、多模态 |
| **Minimax** | M2.5 | Minimax | 编程+Agent | 代码、超长上下文、效率 | ✅ 图文 | 400K | ⚠️ 部分开源 | 中 | 编程、企业级Agent |
| **Llama** | 3.1 70B | Meta | 英文开源基座 | 英文、生态、二次微调 | ⚠️ 需扩展 | 128K | ✅ 开源 | 中 | 英文场景、私有化、二次开发 |


## 其他

- Anaconda是一个包含大量预装数据科学和机器学习库的Python发行版
- PyTorch 是一个开源的机器学习库，主要用于进行计算机视觉（CV）、自然语言处理（NLP）、语音识别等领域的研究和开发

- Token 就是大模型读写文字的 “最小单位”，控制它的上下文记忆、速度、成本、上限

- 流式返回：
    - 响应头配置（最基础）
    - 必须修改 Content-Type
    - 主流用 SSE（Server-Sent Events）：Content-Type: text/event-stream; charset=utf-8
    - 也可用 JSON 流：Content-Type: application/x-ndjson
    
- MCP（Model Context Protocol，模型上下文协议）是一种标准化的AI模型通信协议，旨在让不同模型及外部系统之间高效共享上下文，实现工具调用、插件扩展、多模态处理等功能。它的核心是上下文管理，通过统一接口让模型在执行任务时动态获取外部数据与能力。
全模态（文本 / 图像 / 音频 / 视频）
